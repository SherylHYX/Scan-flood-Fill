## Scan-flood Fill README

### 1 Requirements

- python 2.7
- numpy
- cv2 (opencv)
- skimage
- time
- os

### 2 Dataset

​	The input images for our toy experiment are generated by dilation of eight 200 x 200  basic images.(see code dilation.py and \data\toy_example\input_200\)  Define the property 3-tuple of an image to be (multiple, border, holes), whose entries are all Boolean variables, to represent each of these eight cases. For example, (F,F,T)  means that the image has only one object inside, has no regions whose boundaries meet the border of the whole image but has "holes"  inside regions. This notation will be used to illustrate the comparison on toy examples. To show that our algorithm can also be useful in practical ground truth masks generating process, we also consider images in MSRA10K

### 3 Overview

​	This LIDC_menet model takes in LIDC-IDRI dataset and output the following:

- several caffe models in "snapshot" folder, classified by last characters denoting training proportion and process date. For example, folder "snapshot75-2019-01-03" denotes the trained model for a training proportion of 75% on the date 2019-01-03.

- several caffe models in "attention_iter_110000" folder, classified by last characters denoting training proportion and process date. For example, folder "attention_iter_11000085-2019-01-22" denotes the trained model for a training proportion of 85% on the date 2019-01-22, using the caffe model after 110000 iterations. More specifically, there are four images for each CT image, i.e. "initial file name ( which means the initial name of the file, will be further illustrated later) + _images" means the corresponding JPG file from dicom image, "initial file name + _labels" means the MASK labelled image, "initial file name + _metric_result" means the image combing JPG and model result (can be ignored in our case), and "initial file name + _sal_result" means the model result. For example, "0861_3_6_1_4_1_14519_5_2_1_6279_6001_100384389542220778589635003614_images.jpg" means the corresponding JPG file from dicom image of initial file name "0861_3_6_1_4_1_14519_5_2_1_6279_6001_100384389542220778589635003614", "0861_3_6_1_4_1_14519_5_2_1_6279_6001_100384389542220778589635003614_labels.jpg" means his label, "0861_3_6_1_4_1_14519_5_2_1_6279_6001_100384389542220778589635003614_metric_result.jpg" means the combing image, "0861_3_6_1_4_1_14519_5_2_1_6279_6001_100384389542220778589635003614_sal_result.jpg" means the model result.

- three-channel JPGs using thresholding from dicom files, named by patient number (the first four digits) and uid ("." in uid converted to "_" in order to be distinguished from the "." before file extension) saved in folder "LIDC_JPG0114" and "LIDC_JPG_FULL0114" respectively. "FULL" means we consider also small nodules, i.e. nodules that are smaller than 3 mm. These small nodules are only labeled by centroids in xml files. In terms of the file name, for example, "0861_3_6_1_4_1_14519_5_2_1_6279_6001_100384389542220778589635003614" means it is a CT image of the 861th patient, and its uid is "3.6.1.4.1.14519.5.2.1.6279.6001.100384389542220778589635003614".

- one-channel JPGs using thresholding from dicom files, named by patient number (the first four digits) and uid ("." in uid converted to "_" in order to be distinguished from the "." before file extension) saved in folder "LIDC_JPG0114_single" and "LIDC_JPG_FULL0114_single" respectively. 

- label information using png files (coordinates corrected) , named by patient number (the first four digits) and uid ("." in uid converted to "_" in order to be distinguished from the "." before file extension) saved in folder  "LIDC_MASK0129" ,  "LIDC_MASK0115" , "LIDC_MASK_FULL0115" ,  "LIDC_EDGE0129" ,"LIDC_EDGE0115" and "LIDC_EDGE_FULL0115" respectively. Note that for the 0115 but without "FULL" version, we exclude images merely generated by small nodules, but might include small nodules in some images (this is fixed in the 0129 version) Besides, for training, we just use   "LIDC_MASK0129" and "LIDC_EDGE_0129".

- (not used in training or testing) 14581 instances, each has 4 corresponding files regardless of small nodules(1 jpg from dicom, 1 csv with HU (pixel values) in dicom, 1 edge png file, 1 mask png file, in folder "LIDC_JPG","LIDC_DICOM","LIDC_EDGE","LIDC_MASK" respectively) (note that those labeling files have their coordinates reversed in this version, but corrected in later versions)

- (not used in training or testing) 14581 instances, each has 4 corresponding files regarding small nodules(1 jpg from dicom, 1 csv with HU (pixel values) in dicom, 1 edge png file, 1 mask png file, in folder "LIDC_JPG_FULL","LIDC_DICOM_FULL","LIDC_EDGE_FULL","LIDC_MASK_FULL" respectively) (note that those labeling files have their coordinates reversed in this version, but corrected in later versions)

- (not used in training or testing) renamed files of the above 8 folders in "LIDC_RENAME" folder, and their mapping results, with those excluding small nodules in uid_shuffle_result.txt and those including small nodules in uid_shuffle_result_new.txt, sharing the same first 14581 shuffle results. (note that those labeling files have their coordinates reversed in this version, but corrected in later versions)

- (not used in training or testing) 1 text file and 1 csv file  regardless of small nodules to represent validNodes dictionary, i.e. for those nodules we are dealing with, i.e. validNodes.csv and validNodes.txt

- (not used in training or testing) 1 text file and 1 csv file  regarding of small nodules to represent validNodes dictionary, i.e. for those nodules we are dealing with, i.e. validNodes_full.csv and validNodes_full.txt

  The resulting dataset and corresponding codes are available on https://pan.baidu.com/s/1MTeSPXyt9W6bJe2zGiqLIQ with extraction code lp0y .

​	Our method of data preprocessing is an efficient process with the following advantages:

- file names include information of both patient number and uid, which will be helpful for dividing data into training set and test set, and also useful to trace dicom images
- use the convex character of lung nodules to efficiently fill the masks
- parse the first dicom file in each directory to decide whether this directory is desirable, avoiding repeating judgements, since files in the same smallest directory have the same slice thickness and modality

### 4 Data extraction

​	By studying the descriptions of the dataset(https://wiki.cancerimagingarchive.net/display/Public/LIDC-IDRI#0a43d1d857044c2183deabd2f2f2cd8a), we decide to first extract only lung CT images with slice thickness less than or equal to 2.5mm,  which can be detected by parsing dicom files.  Also, we exclude those nodules with diameter less than 3mm. We achieve the above via the function isValidDcm, taking in the dicom path.

```python
def isValidDcm(dcmPath):
    dcm = pydicom.dcmread(dcmPath)
    try:
        # Check modality
        if  dcm[0x0008, 0x0060].value != 'CT':
            return False
    except:
        return False
    try:
        # Check thichness
        if dcm[0x0018, 0x0050].value > 2.5:
            return False, False, False
    except:
        return False
    return True
```

### 5 Image generation

​	To fit the data in MEnet model, we need jpg and png pairs as input.  From xml files and data extraction, we get valid uids for image generation. Setting those uids to be keys of the validNodes dictionary, we find corresponding dicom files and edgeMaps in xml files. 

​	First we save corresponding numpy array for HU(the Hounsfield unit scale, see https://en.wikipedia.org/wiki/Hounsfield_scale) values into csv files. We then convert dicom files into jpg files, by normalizing HU values(512*512 pixel values in dicom files) to [0,255]. 

​	After that, we generate edgeMaps+centroids png files named after uid and mask png files by filling edgeMaps png files by straight lines. Straight lines are reasonable in that lung nodules are normally almost convex, and with centroids considered, we are less likely to fill outside the nodule area. Filling process is accompanied by morphology close to fill small holes. 

​	Via these process, we obtain four corresponding files for valid dicom files and their valid nodules (i.e.nodules that are at least 3mm in the NOT "FULL" version) as well as the "FULL" version (including small nodules). We obtain one-channel and three-channel data, and both "FULL" and NOT "FULL" versions at the same time.

​	Corresponding codes are as follows: (we use thresholding here, and this code generates "0115" and "0114" datasets)

```python
def output_pre0115_both(current_Path, validNodes, validNodes_full, patientNo):
    # judge whether this is a valid folder of CT images and proper thickness
    for f_dcm in findAllFiles(current_Path, '.dcm'):
        if not isValidDcm(f_dcm):
            return validNodes, validNodes_full
        else:
            break
    # use ET.parse() to parse xml
    for xmlPath in findAllFiles(current_Path, '.xml'):
        tree = ET.parse(xmlPath)
        root = tree.getroot()
        # To store the UID, edgeMaps, centroid of valid nodules
        # first include small nodules and save files to "FULL" folders
        for readSession in root.findall('nih:readingSession', NS):
            noduleNode = readSession.findall('nih:unblindedReadNodule', NS)
            for node in noduleNode:
                is_small_nodule = 0  # Reset the judgement of whether it is a small nodule
                charNode = node.findall('nih:characteristics', NS)
                # Judge whether it is a small nodule
                if charNode is None or len(charNode) == 0:
                    is_small_nodule = 1
                    if INCLUDE_SMALL_NODULE == 0:  # modified by Tianyi
                        # Exclude nodules that have diameter less than 3mm
                        continue
                xmlRois = node.findall('nih:roi', NS)
                for roi in xmlRois:
                    # Exclude nodules that are not real
                    if roi.find('nih:inclusion', NS) is None:
                        continue
                    if roi.find('nih:inclusion', NS).text != 'TRUE':
                        continue
                    # There is abnormal instances that isn't small nodule but has less than 3 edgemaps
                    if len(roi.findall('nih:edgeMap', NS)) < 2:
                        if is_small_nodule == 0:
                            # Exclude nodules that have less than 3 (x,y).
                            continue
                    # Finally get the valid nodes
                    # Parse the UID of the nodule
                    uid = roi.find('nih:imageSOP_UID', NS).text
                    # Create the JPG of the Lung CT
                    for f_dcm in findAllFiles(current_Path, '.dcm'):
                        dcm = pydicom.dcmread(f_dcm)
                        # find the .dcm w.r.t UID in .xml
                        if dcm[0x0008, 0x0018].value == uid:
                            jpgPath = JPG_SAVE_PATH_FULL + str(patientNo) + uid.replace(".", "_") + '.jpg'
                            jpgPath_single = JPG_SAVE_PATH_FULL_single + str(patientNo) + uid.replace(".", "_") + '.jpg'
                            # modified by Yixuan
                            dcm_numpy = dcm.pixel_array
                            convert_from_dicom_to_jpg(dcm_numpy, jpgPath_single)
                            convert_from_dicom_to_jpg_3channel0114(dcm_numpy, jpgPath)
                            break  # end the loop if we have already found the corresponding dicom picture
                    # Parse the coordinates of nodule's edge map
                    edgePath = EDGE_SAVE_PATH_FULL + str(patientNo) + uid.replace(".", "_") + '.png'
                    maskPath = MASK_SAVE_PATH_FULL + str(patientNo) + uid.replace(".", "_") + '.png'
                    if not os.path.exists(edgePath):
                        # initialize .png file for edge png
                        edgePng = np.zeros((512, 512))
                    else:
                        edgePng = mpimg.imread(edgePath)
                    if not os.path.exists(maskPath):
                        # initialize .png file for mask png
                        maskPng = np.zeros((512, 512))
                    else:
                        maskPng = mpimg.imread(maskPath)

                    edgeXY = []
                    edgeMaps = roi.findall('nih:edgeMap', NS)
                    if (is_small_nodule):  # modified by Tianyi
                        # if it is a small nodule
                        for edgeMap in edgeMaps:
                            # Caution: The coordinate in EdgeMap is exactly inversed in the PNG image
                            # Modified by Tianyi 2019-01-15
                            y = int(edgeMap.find('nih:xCoord', NS).text)
                            x = int(edgeMap.find('nih:yCoord', NS).text)
                            centroid = [x, y]
                            radius = 2
                            # define the coordinate of the edge
                            edge_X = [0, 0, 1, 1, -1, -1, -2, -2, -2, 2, 2, 2]
                            edge_Y = [2, -2, 2, -2, 2, -2, 1, 0, -1, 1, 0, -1]
                            for i in range(len(edge_X)):
                                edgePng[x + edge_X[i - 1], y + edge_Y[i - 1]] = 127
                                maskPng[x + edge_X[i - 1], y + edge_Y[i - 1]] = 127
                    else:
                        for edgeMap in edgeMaps:
                            # Caution: The coordinate in EdgeMap is exactly inversed in the PNG image
                            y = int(edgeMap.find('nih:xCoord', NS).text)
                            x = int(edgeMap.find('nih:yCoord', NS).text)
                            edgePng[x][y] = 255
                            maskPng[x][y] = 255
                            edgeXY.append([x, y])
                        # Calculate the centroid
                        xMax = max([_[0] for _ in edgeXY])
                        xMin = min([_[0] for _ in edgeXY])
                        yMax = max([_[1] for _ in edgeXY])
                        yMin = min([_[1] for _ in edgeXY])
                        centroid = [(xMax + xMin) / 2, (yMax + yMin) / 2]
                    if is_small_nodule:
                        edgePng[centroid[0]][centroid[1]] = 127
                        maskPng[centroid[0]][centroid[1]] = 127
                    else:
                        edgePng[centroid[0]][centroid[1]] = 255
                        maskPng[centroid[0]][centroid[1]] = 255
                    # fill the mask, start from the centroid, along a straight line until the edge point
                    for edgePt in edgeXY:
                        edgeX = edgePt[0]
                        edgeY = edgePt[1]
                        stepNo = max(abs(edgeX - centroid[0]), abs(edgeY - centroid[1]), 10)
                        # number of steps, abs is small, we need another integer
                        delX = float(edgeX - centroid[0]) / stepNo
                        delY = float(edgeY - centroid[1]) / stepNo
                        for i in range(stepNo):
                            if (is_small_nodule):
                                maskPng[int(centroid[0] + i * delX)][int(centroid[1] + i * delY)] = 127
                            else:
                                maskPng[int(centroid[0] + i * delX)][int(centroid[1] + i * delY)] = 255
                    # Store the UID, edgeMaps, centroid of valid nodules
                    if uid in validNodes_full.keys():
                        validNodes_full[uid].append([edgeXY, centroid])
                    else:
                        validNodes_full[uid] = [edgeXY, centroid]
                    # edgePng only contains the edgeMaps, while maskPng contains the full mask
                    cv2.imwrite(edgePath, edgePng.astype('uint8'), [int(cv2.IMWRITE_PNG_COMPRESSION), 0])
                    kernel = np.ones((5, 5), np.uint8)
                    maskPng = cv2.morphologyEx(maskPng.astype('uint8'), cv2.MORPH_CLOSE, kernel)
                    # use morphology close to fill the small holes
                    cv2.imwrite(maskPath, maskPng.astype('uint8'), [int(cv2.IMWRITE_PNG_COMPRESSION), 0])

        # then exclude small nodules and save files to those "without 'FULL'" folders
        for readSession in root.findall('nih:readingSession', NS):
            noduleNode = readSession.findall('nih:unblindedReadNodule', NS)
            for node in noduleNode:
                # Exclude nodules that have diameter less than 3mm
                charNode = node.findall('nih:characteristics', NS)
                if charNode is None or len(charNode) == 0:
                    continue
                xmlRois = node.findall('nih:roi', NS)
                for roi in xmlRois:
                    # Exclude nodules that are not real
                    if roi.find('nih:inclusion', NS) is None:
                        continue
                    if roi.find('nih:inclusion', NS).text != 'TRUE':
                        continue
                    # Exclude nodules that have less than 3 (x,y).
                    if len(roi.findall('nih:edgeMap', NS)) < 2:
                        continue
                    # Finally get the valid nodes
                    # Parse the UID of the nodule
                    uid = roi.find('nih:imageSOP_UID', NS).text
                    # Create the JPG of the Lung CT
                    for f_dcm in findAllFiles(current_Path, '.dcm'):
                        dcm = pydicom.dcmread(f_dcm)
                        if dcm[0x0008, 0x0018].value == uid:
                            jpgPath = JPG_SAVE_PATH + str(patientNo) + uid.replace(".", "_") + '.jpg'
                            jpgPath_single = JPG_SAVE_PATH_single + str(patientNo) + uid.replace(".", "_") + '.jpg'
                            # modified by Yixuan
                            dcm_numpy = dcm.pixel_array
                            convert_from_dicom_to_jpg(dcm_numpy, jpgPath_single)
                            convert_from_dicom_to_jpg_3channel0114(dcm_numpy, jpgPath)
                            break  # end the loop if we have already found the corresponding dicom picture
                    # Parse the coordinates of nodule's edge map
                    edgePath = EDGE_SAVE_PATH + str(patientNo) + uid.replace(".", "_") + '.png'
                    maskPath = MASK_SAVE_PATH + str(patientNo) + uid.replace(".", "_") + '.png'
                    if not os.path.exists(edgePath):
                        edgePng = np.zeros((512, 512))
                    else:
                        edgePng = mpimg.imread(edgePath)
                    if not os.path.exists(maskPath):
                        maskPng = np.zeros((512, 512))
                    else:
                        maskPng = mpimg.imread(maskPath)
                    edgeXY = []
                    edgeMaps = roi.findall('nih:edgeMap', NS)

                    for edgeMap in edgeMaps:
                        # Caution: The coordinates in EdgeMap are exactly inversed in the PNG image
                        y = int(edgeMap.find('nih:xCoord', NS).text)
                        x = int(edgeMap.find('nih:yCoord', NS).text)
                        edgePng[x][y] = 255
                        maskPng[x][y] = 255
                        edgeXY.append([x, y])
                    # Calculate the centroid
                    xMax = max([_[0] for _ in edgeXY])
                    xMin = min([_[0] for _ in edgeXY])
                    yMax = max([_[1] for _ in edgeXY])
                    yMin = min([_[1] for _ in edgeXY])
                    centroid = [(xMax + xMin) / 2, (yMax + yMin) / 2]
                    edgePng[centroid[0]][centroid[1]] = 255
                    maskPng[centroid[0]][centroid[1]] = 255
                    # fill the mask, start from the centroid, along a straight line until the edge point
                    for edgePt in edgeXY:
                        edgeX = edgePt[0]
                        edgeY = edgePt[1]
                        stepNo = max(abs(edgeX - centroid[0]), abs(edgeY - centroid[1]), 10)
                        # number of steps, abs is small, we need another integer
                        delX = float(edgeX - centroid[0]) / stepNo
                        delY = float(edgeY - centroid[1]) / stepNo
                        for i in range(stepNo):
                            maskPng[int(centroid[0] + i * delX)][int(centroid[1] + i * delY)] = 255
                     # Store the UID, edgeMaps, centroid of valid nodules
                    if uid in validNodes.keys():
                        validNodes[uid].append([edgeXY, centroid])
                    else:
                        validNodes[uid] = [edgeXY, centroid]
                     #edgePng only contains the edgeMaps, while maskPng contains the FULL mask
                    cv2.imwrite(edgePath, edgePng.astype('uint8'), [int(cv2.IMWRITE_PNG_COMPRESSION), 0])
                    kernel = np.ones((5, 5), np.uint8)
                    maskPng = cv2.morphologyEx(maskPng.astype('uint8'), cv2.MORPH_CLOSE, kernel)
                    # use morphology close to fill the small holes
                    cv2.imwrite(maskPath, maskPng.astype('uint8'), [int(cv2.IMWRITE_PNG_COMPRESSION), 0])

    return validNodes, validNodes_fulldef output_pre(currernt_Path, validNodes):
    # use ET.parse() to parse xml
    for xmlPath in findAllFiles(currernt_Path, '.xml'):
        tree = ET.parse(xmlPath)
        root = tree.getroot()
        # To store the UID, edgeMaps, centroid of valid nodules
        for readSession in root.findall('nih:readingSession', NS):
            noduleNode = readSession.findall('nih:unblindedReadNodule', NS)
            for node in noduleNode:
                # Exclude nodules that have diameter less than 3mm
                charNode = node.findall('nih:characteristics', NS)
                if (charNode is None or len(charNode) == 0):
                    continue
                xmlRois = node.findall('nih:roi', NS)
                for roi in xmlRois:
                    # Exclude nodules that are not real
                    if roi.find('nih:inclusion', NS) is None:
                        continue
                    if roi.find('nih:inclusion', NS).text != 'TRUE':
                        continue
                    # Exclude nodules that have less than 3 (x,y).
                    if len(roi.findall('nih:edgeMap', NS)) < 2:
                        continue
                    # Finally get the valid nodes
                    # Parse the UID of the nodule
                    uid = roi.find('nih:imageSOP_UID', NS).text
                    for f_dcm in findAllFiles(currernt_Path, '.dcm'):
                        dcm = pydicom.dcmread(f_dcm)
                        if dcm[0x0008, 0x0018].value == uid:
                            jpgPath = JPG_SAVE_PATH + uid + '.jpg'
                            # modified by Yixuan
                            dcm_numpy = dcm.pixel_array
                            # save dicom numpy to csv
                            # first create the file
                            np.savetxt(NUMPY_DICOM_SAVE_PATH + uid + ".csv", dcm_numpy, delimiter=",")
                            with open(NUMPY_DICOM_SAVE_PATH + uid + ".csv", 'wb') as f:
                                writer = csv.writer(f)
                                writer.writerows(dcm_numpy)
                            convert_from_dicom_to_jpg(dcm_numpy, jpgPath)
                            break  # end the loop if we have already found the corresponding dicom picture
                    # Parse the coordinates of nodule's edge map
                    edgePath = EDGE_SAVE_PATH + uid + '.png'
                    maskPath = MASK_SAVE_PATH + uid + '.png'
                    if not os.path.exists(edgePath):
                        edgePng = np.zeros((512, 512))
                    else:
                        edgePng = mpimg.imread(edgePath)
                    if not os.path.exists(maskPath):
                        maskPng = np.zeros((512, 512))
                    else:
                        maskPng = mpimg.imread(maskPath)
                    edgeXY = []
                    edgeMaps = roi.findall('nih:edgeMap', NS)

                    for edgeMap in edgeMaps:
                        x = int(edgeMap.find('nih:xCoord', NS).text)
                        y = int(edgeMap.find('nih:yCoord', NS).text)
                        edgePng[x][y] = 255
                        maskPng[x][y] = 255
                        edgeXY.append([x, y])
                    # Calculate the centroid
                    xMax = max([_[0] for _ in edgeXY])
                    xMin = min([_[0] for _ in edgeXY])
                    yMax = max([_[1] for _ in edgeXY])
                    yMin = min([_[1] for _ in edgeXY])
                    centroid = [(xMax + xMin) / 2, (yMax + yMin) / 2]
                    edgePng[centroid[0]][centroid[1]] = 255
                    maskPng[centroid[0]][centroid[1]] = 255
                    # fill the mask, start from the centroid, along a straight line until the edge point
                    for edgePt in edgeXY:
                        edgeX = edgePt[0]
                        edgeY = edgePt[1]
                        stepNo = max(abs(edgeX - centroid[0]), abs(edgeY - centroid[1]), 10)
                        # number of steps, abs is small, we need another integer
                        delX = float(edgeX - centroid[0]) / stepNo
                        delY = float(edgeY - centroid[1]) / stepNo
                        for i in range(stepNo):
                            maskPng[int(centroid[0] + i * delX)][int(centroid[1] + i * delY)] = 255
                     # Store the UID, edgeMaps, centroid of valid nodules
                    if uid in validNodes.keys():
                        validNodes[uid].append([edgeXY, centroid])
                    else:
                        validNodes[uid] = [edgeXY, centroid]
                     #edgePng only contains the edgeMaps, while maskPng contains the full mask
                    cv2.imwrite(edgePath, edgePng.astype('uint8'), [int(cv2.IMWRITE_PNG_COMPRESSION), 0])
                    kernel = np.ones((5, 5), np.uint8)
                    maskPng = cv2.morphologyEx(maskPng.astype('uint8'), cv2.MORPH_CLOSE, kernel)
                    # use morphology close to fill the small holes
                    cv2.imwrite(maskPath, maskPng.astype('uint8'), [int(cv2.IMWRITE_PNG_COMPRESSION), 0])
    return validNodes
```

​	The converting function from dicom to one-channel jpg is:

```python
def convert_from_dicom_to_jpg(img, save_path):
    img[img < -1000] = -1000
    # From HU in [-1000,500],taking <-1000 to -1000 and >500 to 500 before normalization
    img[img > 500] = 500
    # We need float first then convert to int, otherwise we can only get black and white!
    newimg = (((img + 1000.0) / 1500.0) * 255.0).astype('uint8')
    cv2.imwrite(save_path, newimg, [int(cv2.IMWRITE_JPEG_QUALITY), 100])
```

​	For the revised version excluding small nodules, i.e. generating "LIDC_MASK_0129" and "LIDC_EDGE_0129", we have the following code:

```python
def output_pre0129(current_Path, validNodes, validNodes_full, patientNo):
    # judge whether this is a valid folder of CT images and proper thickness
    for f_dcm in findAllFiles(current_Path, '.dcm'):
        if not isValidDcm(f_dcm):
            return validNodes, validNodes_full
        else:
            break
    # use ET.parse() to parse xml
    for xmlPath in findAllFiles(current_Path, '.xml'):
        tree = ET.parse(xmlPath)
        root = tree.getroot()
        # exclude small nodules and save files to those "without 'FULL'" folders
        for readSession in root.findall('nih:readingSession', NS):
            noduleNode = readSession.findall('nih:unblindedReadNodule', NS)
            for node in noduleNode:
                # Exclude nodules that have diameter less than 3mm
                charNode = node.findall('nih:characteristics', NS)
                if charNode is None or len(charNode) == 0:
                    continue
                xmlRois = node.findall('nih:roi', NS)
                for roi in xmlRois:
                    # Exclude nodules that are not real
                    if roi.find('nih:inclusion', NS) is None:
                        continue
                    if roi.find('nih:inclusion', NS).text != 'TRUE':
                        continue
                    # Exclude nodules that have less than 3 (x,y).
                    if len(roi.findall('nih:edgeMap', NS)) < 2:
                        continue
                    # Finally get the valid nodes
                    # Parse the UID of the nodule
                    uid = roi.find('nih:imageSOP_UID', NS).text
                    # Parse the coordinates of nodule's edge map
                    edgePath = EDGE_SAVE_PATH + str(patientNo) + uid.replace(".", "_") + '.png'
                    maskPath = MASK_SAVE_PATH + str(patientNo) + uid.replace(".", "_") + '.png'
                    if not os.path.exists(edgePath):
                        edgePng = np.zeros((512, 512))
                    else:
                        edgePng = mpimg.imread(edgePath)
                    if not os.path.exists(maskPath):
                        maskPng = np.zeros((512, 512))
                    else:
                        maskPng = mpimg.imread(maskPath)
                    edgeXY = []
                    edgeMaps = roi.findall('nih:edgeMap', NS)

                    for edgeMap in edgeMaps:
                        # Caution: The coordinates in EdgeMap are exactly inversed in the PNG image
                        y = int(edgeMap.find('nih:xCoord', NS).text)
                        x = int(edgeMap.find('nih:yCoord', NS).text)
                        edgePng[x][y] = 255
                        maskPng[x][y] = 255
                        edgeXY.append([x, y])
                    # Calculate the centroid
                    xMax = max([_[0] for _ in edgeXY])
                    xMin = min([_[0] for _ in edgeXY])
                    yMax = max([_[1] for _ in edgeXY])
                    yMin = min([_[1] for _ in edgeXY])
                    centroid = [(xMax + xMin) / 2, (yMax + yMin) / 2]
                    edgePng[centroid[0]][centroid[1]] = 255
                    maskPng[centroid[0]][centroid[1]] = 255
                    # fill the mask, start from the centroid, along a straight line until the edge point
                    for edgePt in edgeXY:
                        edgeX = edgePt[0]
                        edgeY = edgePt[1]
                        stepNo = max(abs(edgeX - centroid[0]), abs(edgeY - centroid[1]), 10)
                        # number of steps, abs is small, we need another integer
                        delX = float(edgeX - centroid[0]) / stepNo
                        delY = float(edgeY - centroid[1]) / stepNo
                        for i in range(stepNo):
                            maskPng[int(centroid[0] + i * delX)][int(centroid[1] + i * delY)] = 255
                     # Store the UID, edgeMaps, centroid of valid nodules
                    if uid in validNodes.keys():
                        validNodes[uid].append([edgeXY, centroid])
                    else:
                        validNodes[uid] = [edgeXY, centroid]
                     #edgePng only contains the edgeMaps, while maskPng contains the FULL mask
                    cv2.imwrite(edgePath, edgePng.astype('uint8'), [int(cv2.IMWRITE_PNG_COMPRESSION), 0])
                    kernel = np.ones((5, 5), np.uint8)
                    maskPng = cv2.morphologyEx(maskPng.astype('uint8'), cv2.MORPH_CLOSE, kernel)
                    # use morphology close to fill the small holes
                    cv2.imwrite(maskPath, maskPng.astype('uint8'), [int(cv2.IMWRITE_PNG_COMPRESSION), 0])

    return validNodes, validNodes_full
```

​	For the three-channel case, we have: (we use color red to stand for low HU values, green for middle, and blue for high, within thresholding ranges)

```python 
def convert_from_dicom_to_jpg_3channel0114(img, save_path):
    img[img < -1024] = -1024
    #  for HU not in [-1024,511], we take HU <-1024 to -1024 and HU >511 to 511 before normalization
    img[img > 511] = 511
    # We need float first then convert to int, otherwise we can only get black and white!
    multi_channel_img = np.zeros((img.shape[0], img.shape[1], 3))
    # Colours in JPG are strored in this order [blue, green, red]
    # Initialize to [0,0,0]
    for x in range(512):
        for y in range(512):
            pixelvalue = img[x,y]
            # red channel
            if  pixelvalue< -512:
                multi_channel_img [x,y,2] = (( pixelvalue + 1024.0)/2.0).astype(int)
            else:
                if  pixelvalue < 0:
                    # green channel
                    multi_channel_img [x,y,1] = (( pixelvalue + 512.0)/2.0).astype(int)
                else:
                    # blue channel
                    multi_channel_img [x,y,0] = (( pixelvalue+ 0)/2.0).astype(int)

    cv2.imwrite(save_path, multi_channel_img, [int(cv2.IMWRITE_JPEG_QUALITY), 100])
```

### 6 LIDC_MEnet

​	Our model is autonomous since we do not need to split the data, do the training and testing, renaming

and creating files by ourselves. All we need to do is to input some training proportion and then execute the file LIDC_menet_main_yx.py, which in fact consists of the following processes:

#### 6.1 Split data:

​	Data split includes clearing the origin training and testing folders, and moving new files inside.Explicitly, the training folders are: /train_data/GT_train/ for files in LIDC_MASK_FULL in the LIDC_RENAME folder, /train_data/images_train/ for files in LIDC_JPG_FULL in the LIDC_RENAME folder, /train_data/Images_train_SOBEL/ for files in LIDC_EDGE_FULL in the LIDC_RENAME folder; the testing folders are: /test_data/Images_test/ for files in LIDC_JPG_FULL in the LIDC_RENAME folder, /test_data/LIDC_EDGE/ for files in LIDC_EDGE_FULL in the LIDC_RENAME folder, /test_data/LIDC_MASK/ for files in LIDC_MASK_FULL in the LIDC_RENAME folder.

​	During this process, we make use of file names, taking different patients to either training set or test set. 

​	This process uses the following:

```python
def del_file(path):
    # delete files
    for i in os.listdir(path):
        path_file = os.path.join(path, i)
        if os.path.isfile(path_file):
            os.remove(path_file)
        else:
            del_file(path_file)

def split_data_details1(originPath, trainPath, testPath, split_proportion):
    del_file(trainPath) # first clean the directories
    del_file(testPath)
    for root, dirs, filess in os.walk(originPath):
        for files in filess:
            if(extractPatientNo(files) <= int(split_proportion * 1012)):
                os.system('cp {} {}'.format(os.path.join(originPath, files),\
                os.path.join(trainPath, files)))
            else:
                os.system('cp {} {}'.format(os.path.join(originPath, files),\
                os.path.join(testPath, files)))

def split_data1(split_proportion):
    MASK_PATH = '/workspace/LIDC_MASK0129/'
    EDGE_PATH = '/workspace/LIDC_EDGE0129/'
    JPG_PATH = '/workspace/LIDC_JPG0114_single/'

    MASK_TRAIN_PATH = '/workspace/LIDC_menet_test/LIDC_menet_model/train_data/GT_train/'
    EDGE_TRAIN_PATH = '/workspace/LIDC_menet_test/LIDC_menet_model/train_data/Images_train_SOBEL/'
    JPG_TRAIN_PATH = '/workspace/LIDC_menet_test/LIDC_menet_model/train_data/Images_train/'

    MASK_TEST_PATH = '/workspace/LIDC_menet_test/LIDC_menet_model/test_data/LIDC_MASK/'
    EDGE_TEST_PATH = '/workspace/LIDC_menet_test/LIDC_menet_model/test_data/LIDC_EDGE/'
    JPG_TEST_PATH = '/workspace/LIDC_menet_test/LIDC_menet_model/test_data/Images_test/'
    split_data_details1(MASK_PATH, MASK_TRAIN_PATH, MASK_TEST_PATH, split_proportion)
    split_data_details1(EDGE_PATH, EDGE_TRAIN_PATH, EDGE_TEST_PATH, split_proportion)
    split_data_details1(JPG_PATH, JPG_TRAIN_PATH, JPG_TEST_PATH, split_proportion)
```

#### 6.2 Training

​	We use MEnet here, where generated models can be found in the "snapthot" folder.

#### 6.3 Testing

​	we use MEnet again, where testing results can be found in the "attention_iter_110000" folder.

#### 6.4 Renaming files

​	Rename the trained model folder and testing result folder to include the training proportion and process date. Then we get:

- several caffe models in "snapshot" folder, classified by last characters denoting training proportion and process date. For example, folder "snapshot75-2019-01-03" denotes the trained model for a training proportion of 75% on the date 2019-01-03.
- several caffe models in "attention_iter_110000" folder, classified by last characters denoting training proportion and process date. For example, folder "attention_iter_11000075-2019-01-03" denotes the trained model for a training proportion of 75% on the date 2019-01-03.

#### 6.5 Create folders

​	We create the "snapshot" folder and the "attention_iter_110000" folder for the next model.

​	Therefore, the whole process can be integrated into a python file: LIDC_menet_main_1.py, which has the main function as:

```python
def main_1(sliptProportion):
    # 1. split the data
    # 1.1 exclude small nodules
    modelName = 'attention_iter_110000_' + str(int(100 * sliptProportion)) + '-' + time.strftime("%Y-%m-%d",time.localtime())
    testName = str(int(100 * sliptProportion)) + '-' + time.strftime("%Y-%m-%d", time.localtime())
    try:
        print('start split data (exclude small nodules)')
        split_data1(sliptProportion)
    except:
        print('split failed')
        return 0
    else:
        print('split done')
    # 2. training
    print('start training model: ' + modelName)
    try:
        os.system("python training.py")
    except:
        print('training fail')
        return 0
    else:
        print('training finished')
    # 3. testing
    print('start testing')
    try:
        print(testing1.GV.test_images_num)
        os.system("python testing1.py")
    except:
        print('testing fail')
        return 0
    else:
        print('testing finished')
    # 4. rename
    os.rename('/workspace/LIDC_menet_test/LIDC_menet_model/attention_iter_110000/', '/workspace/LIDC_menet_test/LIDC_menet_model/attention_iter_110000' + testName + '/')
    os.rename('/workspace/LIDC_menet_test/LIDC_menet_model/model/snapshot/', '/workspace/LIDC_menet_test/LIDC_menet_model/model/snapshot' + testName + '/')
    # 5. create new directories
    os.mkdir("/workspace/LIDC_menet_test/LIDC_menet_model/attention_iter_110000/")
    os.mkdir("/workspace/LIDC_menet_test/LIDC_menet_model/model/snapshot/")
```

In this way, we can train and test several models simply by running one python program, say, using the following:

```python
if __name__ == '__main__':
    main_yx(0.95)
    main_yx(0.85)
    main_yx(0.75)
    main_yx(0.65)
```

### 7 Discussions

#### 7.1 HU normalization

​	For HU normalization map, we have various choices. In this model, for HU not in [-1000,500], we take HU <-1000 to -1000 and HU >500 to 500 before normalization, then use a linear map to convert [-1000,500] to [0,255] and then make all values integers. We can actually choose another interval before normalization, say [-1000,400], [-1500, 1500] and so on. The length of the interval decides the accuracy of our transformation. Due to limited number jpg pixels can attain, longer interval reduces accuracy to differentiate nearby HU values, thus  the interval should be as short as possible. However, it is reasonable to make a distinction between different parts of a human body, thus we need to include -1000(air) and +400(cancellous bones). When testing on nodule HU values, we find that they are around 300, not far from 400, thus we extend the interval to 500 to avoid their normalized value too close to 255.

#### 7.2 CSV vs JPG

​	Since for each valid instance, we generate 4 files, we can make some comparisons based on them. For example, for covariates, we can consider either jpg files or csv files. The difference is that csv files contain the raw HU values without normalization, thus has wider range and no loss of HU information, while jpg files convert each HU value to an integer in [0,255], which means jpg files are at risk of losing information. 

#### 7.3 One channel vs Three channels

​	By thresholding, we have to lose some information. In order to maintain enough information from the original dicom file, we use a map to take HU values to a certain interval, and then convert them to JPG images. During this process, we try two ways: one is to map to one-channel images, the other is to map to three channel ones.  In the three-channel version, we use different colors to represent different range of HU values. Specifically, we first map all HU values lower than -1024 to -1024, and higher than 511 to 511. We choose the range to be 3 * 512 = 3 * 256 * 2, so that each HU value will only be squeezed half, not losing so much information. Then, we take the maps from revised HU values to three channels respectively, i.e.: [-1024, -513] -> [0,255] (red), [-512, -1] -> [0.255] (green) and [0,511] -> [0,255] (blue). However, when we compare the training results, three-channel ones are not as good as one-channel ones, although we only have [-1000,500] ->[0,255] for one-channel images, in which we have to squeeze the HU values more. The reason for this may be that while three-channel images represent HU values well, the "low-middle-high" logic may be difficult to understand for the model.

#### 7.4 Small Nodules Inclusion and Evaluation

​	Most articles using the LIDC-IDRI dataset do not include small nodules. One reason is that xml files providing ground truth information merely contain centroid coordinates of small nodules, whose diameter is less than 3mm. However, when we tested our first models disregarding small nodules, we found that some of the results given by our models provide more nodules than the ground truth label image with nodule masks excluding small ones. In order to know whether these excessive nodules are small nodules detected by our trained model, or simply some mistaken results, we would like to also include information about small nodules in our evaluation, or even, training process. Therefore, we include centroids and draw some imaginary small circles to represent them, since we have no knowledge about their shapes or exact diameters. Furthermore, to distinct them from labelled nodules whose diameters are at least 3mm, we choose gray color(value 127) to draw small nodules.